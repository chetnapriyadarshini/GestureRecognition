{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d82d4778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "import datetime\n",
    "from glob import glob\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5913d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfce3656",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('/datasets/Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('/datasets/Project_data/val.csv').readlines())\n",
    "batch_size = 100 #experiment with the batch size\n",
    "img_idx = [0,2,4,6,8,10,12,14,16,18,20,22,24,26,28]#create a list of image numbers you want to use\n",
    "num_frames = len(img_idx)\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b53bafe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_channel(channel):\n",
    "    mean = np.mean(channel)\n",
    "    std = np.std(channel)\n",
    "    normalized_channel = (channel - mean) / std\n",
    "    return normalized_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25cab9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size, width, height):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(t)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,num_frames,width,height,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,num_classes)) # batch_labels is the one hot representation of the output\n",
    "            print(batch_data.shape)\n",
    "            print(batch_labels.shape)\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "\n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape\n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    image = resize(image, (width, height))\n",
    "\n",
    "                    batch_data[folder,idx,:,:,0] = normalize_channel(image[:,:,0]) #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,1] = normalize_channel(image[:,:,1]) #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = normalize_channel(image[:,:,2]) #normalise and feed in the image\n",
    "\n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "\n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        remaining_batches = len(t)%batch_size\n",
    "        print(remaining_batches)\n",
    "        if remaining_batches > 0:\n",
    "            batch_data = np.zeros((remaining_batches,num_frames,width,height,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((remaining_batches,num_classes)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(remaining_batches): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "\n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape\n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    image = resize(image, (width, height))\n",
    "\n",
    "                    batch_data[folder,idx,:,:,0] = normalize_channel(image[:,:,0]) #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,1] = normalize_channel(image[:,:,1]) #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = normalize_channel(image[:,:,2]) #normalise and feed in the image\n",
    "\n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f5219b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 3\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = '/datasets/Project_data/train'\n",
    "val_path = '/datasets/Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 3 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)\n",
    "img_width = 100\n",
    "img_height = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cc3301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07ecc379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 10:38:05.053071: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-08-26 10:38:05.053133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14800 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:41:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 15, 100, 100, 16)  448      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 15, 100, 100, 32)  4640     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 15, 320000)       0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 15, 32)            30723264  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 480)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 2405      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,730,757\n",
      "Trainable params: 30,730,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model = Sequential()\n",
    "rnn_model.add(TimeDistributed(Conv2D(16, (3, 3), padding='same', activation='relu'), input_shape=(num_frames,img_height, img_width, 3)))\n",
    "rnn_model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same', activation='relu')))  # Added another Conv2D layer\n",
    "rnn_model.add(TimeDistributed(Flatten()))  # Flatten the output before passing to GRU\n",
    "rnn_model.add(GRU(32, return_sequences=True))\n",
    "# rnn_model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "rnn_model.add((Flatten()))\n",
    "rnn_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "rnn_model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07876c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size, img_width, img_height)\n",
    "val_generator = generator(val_path, val_doc, batch_size, img_width, img_height)\n",
    "#next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cca0c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecayLR(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, base_lr=0.001, decay_epoch=1):\n",
    "        super(DecayLR, self).__init__()\n",
    "        self.base_lr = base_lr\n",
    "        self.decay_epoch = decay_epoch\n",
    "        self.lr_history = []\n",
    "\n",
    "    # set lr on_train_begin\n",
    "    def on_train_begin(self, logs={}):\n",
    "        tf.keras.backend.set_value(self.model.optimizer.learning_rate, self.base_lr)\n",
    "\n",
    "    # change learning rate at the end of epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        new_lr = self.base_lr * (0.5 ** (epoch // self.decay_epoch))\n",
    "        self.lr_history.append(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        tf.keras.backend.set_value(self.model.optimizer.learning_rate, new_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6697c590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "\n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "\n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='auto', min_lr=0.01)\n",
    "#DecayLR(base_lr = 0.1)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b7847f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd8fa2c",
   "metadata": {},
   "source": [
    "ABLATION EXPERIMENT: Batch_size = 100, Epochs: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c4cbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  /datasets/Project_data/train ; batch size = 100\n",
      "(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "Epoch 1/3\n",
      "(100, 15, 100, 100, 3)\n",
      "(100, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 08:37:48.314133: I tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to model_init_2024-08-2608_37_28.754076/model-00001-1.60224-0.25000.h5\n",
      "1/7 [===>..........................] - ETA: 44s - loss: 1.6022 - categorical_accuracy: 0.2500(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00001: saving model to model_init_2024-08-2608_37_28.754076/model-00001-2.06575-0.22000.h5\n",
      "2/7 [=======>......................] - ETA: 35s - loss: 2.0658 - categorical_accuracy: 0.2200(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00001: saving model to model_init_2024-08-2608_37_28.754076/model-00001-2.11940-0.20667.h5\n",
      "3/7 [===========>..................] - ETA: 31s - loss: 2.1194 - categorical_accuracy: 0.2067(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00001: saving model to model_init_2024-08-2608_37_28.754076/model-00001-2.09063-0.19250.h5\n",
      "4/7 [================>.............] - ETA: 26s - loss: 2.0906 - categorical_accuracy: 0.1925(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00001: saving model to model_init_2024-08-2608_37_28.754076/model-00001-2.03152-0.20000.h5\n",
      "5/7 [====================>.........] - ETA: 18s - loss: 2.0315 - categorical_accuracy: 0.200063\n",
      "\n",
      "Epoch 00001: saving model to model_init_2024-08-2608_37_28.754076/model-00001-1.97649-0.20333.h5\n",
      "6/7 [========================>.....] - ETA: 9s - loss: 1.9765 - categorical_accuracy: 0.2033 (100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00001: saving model to model_init_2024-08-2608_37_28.754076/model-00001-1.94594-0.19910.h5\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.9459 - categorical_accuracy: 0.1991Source path =  /datasets/Project_data/val ; batch size = 100\n",
      "(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "0\n",
      "(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "7/7 [==============================] - 86s 13s/step - loss: 1.9459 - categorical_accuracy: 0.1991 - val_loss: 1.6107 - val_categorical_accuracy: 0.2200 - lr: 0.0010\n",
      "Epoch 2/3\n",
      "(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00002: saving model to model_init_2024-08-2608_37_28.754076/model-00002-1.57135-0.26000.h5\n",
      "1/7 [===>..........................] - ETA: 7s - loss: 1.5713 - categorical_accuracy: 0.2600(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00002: saving model to model_init_2024-08-2608_37_28.754076/model-00002-1.57162-0.22500.h5\n",
      "2/7 [=======>......................] - ETA: 50s - loss: 1.5716 - categorical_accuracy: 0.2250(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00002: saving model to model_init_2024-08-2608_37_28.754076/model-00002-1.56089-0.27667.h5\n",
      "3/7 [===========>..................] - ETA: 41s - loss: 1.5609 - categorical_accuracy: 0.2767(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00002: saving model to model_init_2024-08-2608_37_28.754076/model-00002-1.55816-0.29000.h5\n",
      "4/7 [================>.............] - ETA: 29s - loss: 1.5582 - categorical_accuracy: 0.2900(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00002: saving model to model_init_2024-08-2608_37_28.754076/model-00002-1.55513-0.30800.h5\n",
      "5/7 [====================>.........] - ETA: 19s - loss: 1.5551 - categorical_accuracy: 0.308063\n",
      "\n",
      "Epoch 00002: saving model to model_init_2024-08-2608_37_28.754076/model-00002-1.55792-0.30333.h5\n",
      "6/7 [========================>.....] - ETA: 9s - loss: 1.5579 - categorical_accuracy: 0.3033 (100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00002: saving model to model_init_2024-08-2608_37_28.754076/model-00002-1.55757-0.30618.h5\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.5576 - categorical_accuracy: 0.30620\n",
      "(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "0\n",
      "(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "7/7 [==============================] - 81s 13s/step - loss: 1.5576 - categorical_accuracy: 0.3062 - val_loss: 1.6368 - val_categorical_accuracy: 0.2800 - lr: 0.0010\n",
      "Epoch 3/3\n",
      "(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00003: saving model to model_init_2024-08-2608_37_28.754076/model-00003-1.49443-0.38000.h5\n",
      "1/7 [===>..........................] - ETA: 6s - loss: 1.4944 - categorical_accuracy: 0.3800(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00003: saving model to model_init_2024-08-2608_37_28.754076/model-00003-1.55553-0.35500.h5\n",
      "2/7 [=======>......................] - ETA: 49s - loss: 1.5555 - categorical_accuracy: 0.3550(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00003: saving model to model_init_2024-08-2608_37_28.754076/model-00003-1.56497-0.34000.h5\n",
      "3/7 [===========>..................] - ETA: 38s - loss: 1.5650 - categorical_accuracy: 0.3400(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00003: saving model to model_init_2024-08-2608_37_28.754076/model-00003-1.58000-0.34000.h5\n",
      "4/7 [================>.............] - ETA: 29s - loss: 1.5800 - categorical_accuracy: 0.3400(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00003: saving model to model_init_2024-08-2608_37_28.754076/model-00003-1.57237-0.34600.h5\n",
      "5/7 [====================>.........] - ETA: 19s - loss: 1.5724 - categorical_accuracy: 0.346063\n",
      "\n",
      "Epoch 00003: saving model to model_init_2024-08-2608_37_28.754076/model-00003-1.56109-0.34833.h5\n",
      "6/7 [========================>.....] - ETA: 9s - loss: 1.5611 - categorical_accuracy: 0.3483 (100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "\n",
      "Epoch 00003: saving model to model_init_2024-08-2608_37_28.754076/model-00003-1.56072-0.34540.h5\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.5607 - categorical_accuracy: 0.34540\n",
      "(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "0\n",
      "(100, 15, 100, 100, 3)\n",
      "(100, 5)\n",
      "7/7 [==============================] - 80s 13s/step - loss: 1.5607 - categorical_accuracy: 0.3454 - val_loss: 1.6175 - val_categorical_accuracy: 0.2900 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f65b125e550>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
    "                    callbacks=callbacks_list, validation_data=val_generator,\n",
    "                    validation_steps=validation_steps, class_weight=None, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc478f5",
   "metadata": {},
   "source": [
    "We can see that the model is learning as loss is decreasing and categorical_accuracy is increasing. So our model architure is correct\n",
    "We will now reduce our batch_size and increase epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c110b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3fd3e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size, img_width, img_height)\n",
    "val_generator = generator(val_path, val_doc, batch_size, img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "325fb259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 11:28:46.852188: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-08-26 11:28:46.852248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14800 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:41:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 15, 100, 100, 16)  448      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 15, 160000)       0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 15, 16)            7680864   \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 240)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 1205      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,682,517\n",
      "Trainable params: 7,682,517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model2 = Sequential()\n",
    "rnn_model2.add(TimeDistributed(Conv2D(16, (3, 3), padding='same', activation='relu'), input_shape=(num_frames,img_height, img_width, 3)))\n",
    "rnn_model2.add(TimeDistributed(Flatten()))  # Flatten the output before passing to GRU\n",
    "rnn_model2.add(GRU(16, return_sequences=True))\n",
    "# rnn_model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "rnn_model2.add((Flatten()))\n",
    "rnn_model2.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "rnn_model2.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "rnn_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159b1edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  /datasets/Project_data/train ; batch size = 64\n",
      "(64, 15, 100, 100, 3)\n",
      "(64, 5)\n",
      "Epoch 1/10\n",
      "(64, 15, 100, 100, 3)\n",
      "(64, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 11:29:02.973910: I tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 27s - loss: 1.6699 - categorical_accuracy: 0.1719(64, 15, 100, 100, 3)\n",
      "(64, 5)\n",
      "2/7 [=======>......................] - ETA: 19s - loss: 1.8764 - categorical_accuracy: 0.1562(64, 15, 100, 100, 3)\n",
      "(64, 5)\n",
      "3/7 [===========>..................] - ETA: 19s - loss: 1.8692 - categorical_accuracy: 0.1823(64, 15, 100, 100, 3)\n",
      "(64, 5)\n",
      "4/7 [================>.............] - ETA: 15s - loss: 1.8642 - categorical_accuracy: 0.1914(64, 15, 100, 100, 3)\n",
      "(64, 5)\n",
      "5/7 [====================>.........] - ETA: 11s - loss: 1.8338 - categorical_accuracy: 0.1969(64, 15, 100, 100, 3)\n",
      "(64, 5)\n",
      "6/7 [========================>.....] - ETA: 5s - loss: 1.8373 - categorical_accuracy: 0.1875 (64, 15, 100, 100, 3)\n",
      "(64, 5)\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.8251 - categorical_accuracy: 0.1987Source path =  /datasets/Project_data/val ; batch size = 64\n",
      "(64, 15, 100, 100, 3)\n",
      "(64, 5)\n"
     ]
    }
   ],
   "source": [
    "rnn_model2.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
    "                    callbacks=callbacks_list, validation_data=val_generator,\n",
    "                    validation_steps=validation_steps, class_weight=None, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded1a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf /home/.local/share/Trash/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba0cda9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hello' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_208/3305111549.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhello\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hello' is not defined"
     ]
    }
   ],
   "source": [
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb0e9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
